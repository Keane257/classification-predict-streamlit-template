{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgI/kFQgFcmEZD6ODMS+AE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicafar147/classification-predict-streamlit-template/blob/Preprocessing/preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TVMI3wj7sB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "60cc734d-0bd8-429c-9957-062387bd5cc2"
      },
      "source": [
        "!pip install contractions"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: textsearch in /usr/local/lib/python3.6/dist-packages (from contractions) (0.0.17)\n",
            "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_e9WjyW7zRQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5f9d47d0-b071-4297-9320-5546cc7d86a9"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-deep')\n",
        "\n",
        "# text preprocessing\n",
        "import re\n",
        "import string\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import Word\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "# models\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZY3j6fc7zZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/monicafar147/classification-predict-streamlit-template/master/climate-change-belief-analysis/train.csv\")\n",
        "test = pd.read_csv(\"https://raw.githubusercontent.com/monicafar147/classification-predict-streamlit-template/master/climate-change-belief-analysis/test.csv\")"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0PZTMaE7zcn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "f8bc4b43-3c12-40d9-f280-7987be97c584"
      },
      "source": [
        "print(\"Train\\n\")\n",
        "print(train.head(5))\n",
        "print(\"\\nTest\")\n",
        "print(test.head(5))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train\n",
            "\n",
            "   sentiment                                            message  tweetid\n",
            "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
            "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
            "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
            "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
            "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954\n",
            "\n",
            "Test\n",
            "                                             message  tweetid\n",
            "0  Europe will now be looking to China to make su...   169760\n",
            "1  Combine this with the polling of staffers re c...    35326\n",
            "2  The scary, unimpeachable evidence that climate...   224985\n",
            "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
            "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H59B5hNC7zfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _preprocess(data):\n",
        "  df = data.copy()\n",
        "\n",
        "  # apply lowercase to data\n",
        "  data['message'] = data['message'].apply(lambda word: ''.join(word.lower()))\n",
        "\n",
        "  # function to remove contraction\n",
        "  def remove_contraction(row):\n",
        "    fixed = [contractions.fix(word) for word in row.split()]\n",
        "    return ' '.join(map(str,fixed))\n",
        "\n",
        "  # replace contractions\n",
        "  df['message'] = np.vectorize(remove_contraction)(df['message'])\n",
        "\n",
        "  # function to remove patterns\n",
        "  def remove_pattern(text,pattern,replacement=''):\n",
        "    remove_this = re.findall(pattern, text)\n",
        "    for item in remove_this:\n",
        "      text = re.sub(item, replacement, text)\n",
        "    return text\n",
        "\n",
        "  # remove URL\n",
        "  df['message'] = df['message'].apply(lambda word: re.split('https:\\/\\/.*', str(word))[0])\n",
        "\n",
        "  # remove punctuation\n",
        "  df['message'] = df['message'].apply(lambda word: word.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "  # remove stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  data['message'] = data['message'].apply(lambda word: ' '.join(word for word in word.split() if word not in stop_words))\n",
        "\n",
        "  # remove retweet as rt\n",
        "  df['message'] = np.vectorize(remove_pattern)(df['message'],\"RT[\\w]*\")\n",
        "  return df"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tq3_kotW7zhr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trained = train[['sentiment','message','tweetid']]\n",
        "tested = test[['message','tweetid']]"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvejzL-O8aZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_processed = _preprocess(trained)\n",
        "test_processed = _preprocess(tested)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOgreYHI8acf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Splitting the labels and features\n",
        "X = train_processed['message']\n",
        "y = train_processed['sentiment']\n",
        "\n",
        "# Splitting the labels and fetures into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VX75tvPA8h2O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 97,
      "outputs": []
    }
  ]
}