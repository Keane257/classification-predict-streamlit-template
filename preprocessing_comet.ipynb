{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing_comet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monicafar147/classification-predict-streamlit-template/blob/Preprocessing/preprocessing_comet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XweBu-_x9Vj",
        "colab_type": "text"
      },
      "source": [
        "## Introduction to Comet ML  \n",
        "\n",
        "Comet is a great tool for model versioning and experimentation as it records the parameters and conditions from each of your experiements- allowing you to reproduce your results, or go back to a previous version of your experiment.  \n",
        "\n",
        "To create an account, visit https://www.comet.ml/  \n",
        "Follow the instructions for a single user account. Once that is created, you will see a project folder. That is where the records of your experiments can be viewed. \n",
        "\n",
        "Comet has an abundance of tutorials and scripts, we're just going to run through this notebook to get you started on the right track. For this illustration, we will be using one of the examples found on the Comet ML GitHub repo.\n",
        "\n",
        "To begin with, you should install as illustrated below if you don't already have it. *Always import Experiment at the top of your notebook/script.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wd_iEgx6j2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "09ed136b-5f54-4e52-f6c9-cbb0a555eb77"
      },
      "source": [
        "!pip install comet_ml"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: comet_ml in /usr/local/lib/python3.6/dist-packages (3.1.11)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.23.0)\n",
            "Requirement already satisfied: everett[ini]>=1.0.1; python_version >= \"3.0\" in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.0.2)\n",
            "Requirement already satisfied: netifaces>=0.10.7 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.10.9)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from comet_ml) (1.12.0)\n",
            "Requirement already satisfied: websocket-client>=0.55.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.57.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (7.352.0)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (2.6.0)\n",
            "Requirement already satisfied: comet-git-pure>=0.19.11 in /usr/local/lib/python3.6/dist-packages (from comet_ml) (0.19.16)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2020.4.5.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18.4->comet_ml) (1.24.3)\n",
            "Requirement already satisfied: configobj; extra == \"ini\" in /usr/local/lib/python3.6/dist-packages (from everett[ini]>=1.0.1; python_version >= \"3.0\"->comet_ml) (5.0.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cObkea-S7Y85",
        "colab_type": "text"
      },
      "source": [
        "You will see an API key button at the top of the page when you click on an experiment- use this key as illustrated below to link your current workspace to comet. (If a project is empty, the code below will autogenerate for you on the project page, just copy and paste it in here)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5cRjXOH7aTX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3e28b610-d788-4d6a-8541-b01b9a5faf5b"
      },
      "source": [
        "# import comet_ml in the top of your file\n",
        "from comet_ml import Experiment\n",
        "    \n",
        "# Add the following code anywhere in your machine learning file\n",
        "experiment = Experiment(api_key=\"rBqQ3hDuEa6xVpT9ns5Tz1dVt\",\n",
        "                        project_name=\"nlp-climate-change\", workspace=\"monicafar147\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/monicafar147/nlp-climate-change/7a98e5b6512f4fb09e348f5a7fde54da\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dN3PMg07s0Q",
        "colab_type": "text"
      },
      "source": [
        "Import the rest of your necessary libraries as you usually would. For this demonstration we will be using the breast cancer dataset for classification so we will also import that from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAAlRIAWCRmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "076484e5-e4eb-4668-d3e2-6400c165672d"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.style.use('seaborn-deep')\n",
        "\n",
        "# text preprocessing\n",
        "import re\n",
        "import string\n",
        "import contractions\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import Word\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from string import punctuation \n",
        "\n",
        "# models\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfyTp5fLCk6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"https://raw.githubusercontent.com/monicafar147/classification-predict-streamlit-template/master/climate-change-belief-analysis/train.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEnvESeaI5EK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "70617d8c-f07c-4c3c-ea8c-5ea61690fbc2"
      },
      "source": [
        "train['message']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        PolySciMajor EPA chief doesn't think carbon di...\n",
              "1        It's not like we lack evidence of anthropogeni...\n",
              "2        RT @RawStory: Researchers say we have three ye...\n",
              "3        #TodayinMaker# WIRED : 2016 was a pivotal year...\n",
              "4        RT @SoyNovioDeTodas: It's 2016, and a racist, ...\n",
              "                               ...                        \n",
              "15814    RT @ezlusztig: They took down the material on ...\n",
              "15815    RT @washingtonpost: How climate change could b...\n",
              "15816    notiven: RT: nytimesworld :What does Trump act...\n",
              "15817    RT @sara8smiles: Hey liberals the climate chan...\n",
              "15818    RT @Chet_Cannon: .@kurteichenwald's 'climate c...\n",
              "Name: message, Length: 15819, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H59B5hNC7zfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _preprocess(data):\n",
        "  df = data.copy()\n",
        "\n",
        "  # apply lowercase to data\n",
        "  data['message'] = data['message'].apply(lambda word: ''.join(word.lower()))\n",
        "\n",
        "  # function to remove contraction\n",
        "  def remove_contraction(row):\n",
        "    fixed = [contractions.fix(word) for word in row.split()]\n",
        "    return ' '.join(map(str,fixed))\n",
        "\n",
        "  # replace contractions\n",
        "  df['message'] = np.vectorize(remove_contraction)(df['message'])\n",
        "\n",
        "  # function to remove patterns\n",
        "  def remove_pattern(text,pattern,replacement=''):\n",
        "    remove_this = re.findall(pattern, text)\n",
        "    for item in remove_this:\n",
        "      text = re.sub(item, replacement, text)\n",
        "    return text\n",
        "\n",
        "  # remove URL\n",
        "  df['message'] = df['message'].apply(lambda word: re.split('https:\\/\\/.*', str(word))[0])\n",
        "\n",
        "  # remove punctuation\n",
        "  df['message'] = df['message'].apply(lambda word: word.translate(str.maketrans('', '', string.punctuation)))\n",
        "\n",
        "  # remove stopwords\n",
        "  stop_words = stopwords.words('english')\n",
        "  data['message'] = data['message'].apply(lambda word: ' '.join(word for word in word.split() if word not in stop_words))\n",
        "\n",
        "  # remove retweet as rt\n",
        "  df['message'] = np.vectorize(remove_pattern)(df['message'],\"RT[\\w]*\")\n",
        "  return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg4LRudzPQeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _preprocess_V2(tweet):\n",
        "    stopwords_list = set(stopwords.words('english') + list(punctuation))\n",
        "    tweet = tweet.lower() # convert text to lower-case\n",
        "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
        "    tweet = re.sub(r\"\\W\", \" \", tweet) # remove usernames\n",
        "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
        "    tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
        "    tweets = [word for word in tweet if word not in stopwords_list]\n",
        "    return \" \".join(tweets) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFc3kRyjWZW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _preprocess_V3(tweet):\n",
        "  tweet = tweet.lower()\n",
        "  tweet = re.sub(r\"\\W\", \" \", tweet)\n",
        "  tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) \n",
        "  tweet = word_tokenize(tweet)\n",
        "  stopwords_list = set(stopwords.words('english') + list(punctuation))\n",
        "  tweets = [word for word in tweet if word not in stopwords_list]\n",
        "  return \" \".join(tweet)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUN64j3XQdc-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "outputId": "5fba62b9-3f36-48f1-c997-4f141e9887f0"
      },
      "source": [
        "  >>> import nltk\n",
        "  >>> nltk.download('punkt')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M4ggtRcEdlk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting the labels and features\n",
        "train_processed = train['message'].apply(_preprocess_V3)\n",
        "X = train_processed\n",
        "y = train['sentiment']"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNhE-YUpIq1V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "54c86c39-9f26-46ea-af23-f83164f30a64"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'polyscimajor epa chief doesn t think carbon dioxide is main cause of global warming and wait what https t co yelvcefxkc via mashable'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_KDcC6O_uon",
        "colab_type": "text"
      },
      "source": [
        "Split your data into train and test sets, keep in mind that you need to set a random state for your results to be reproduced!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHBLubxt_b2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEbra1uoFYYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeOOCDSYFaR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply model on train data using Linear SVC:\n",
        "svc = Pipeline([('tfidf',TfidfVectorizer()),('classify',LinearSVC())])\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "#apply model on test data\n",
        "y_pred = svc.predict(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn57DHbLQSyF",
        "colab_type": "text"
      },
      "source": [
        "## Results\n",
        "\n",
        "Now that our model has trained, we can have a look at the results- Below is a confusion matrix indicating that at first glance, we have a fairly good model going. We then save the F1 score, Precision, and Recall as individual variables to go into our metric dictionary for logging.\n",
        "\n",
        "P.S. have a look at the Comet tutorial page for interesting confusion matrix plots."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPerWtdRGFvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "8a5292c5-9306-43ed-9c73-3499e599f820"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"\\nResults\\nConfusion matrix \\n {}\".format(\n",
        "    confusion_matrix(y_test, y_pred)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Results\n",
            "Confusion matrix \n",
            " [[ 66  13  41   6]\n",
            " [ 12  95 103  14]\n",
            " [ 17  33 774  71]\n",
            " [  4   3  51 279]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arEXfiZPGLOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Saving each metric to add to a dictionary for logging\n",
        "report = classification_report(y_test, y_pred)\n",
        "matrix = confusion_matrix(y_test, y_pred)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1kDE76cGRSd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dictionaries for the data we want to log\n",
        "\n",
        "params = {\"preprocessing\":  \"_preprocess_V3(data)\",\n",
        "          \"keeps username\":\"True\",\n",
        "          \"keeps hashtags\":\"True\",\n",
        "          \"keeps URL\":\"splits URL up\",\n",
        "          \"removes puncutation\":\"string punctuation\",\n",
        "          \"use stopwords\":\"stopwords.words('english')\",\n",
        "          \"model_type\": \"LinearSVC\",\n",
        "          }\n",
        "\n",
        "metrics = {\"report\" : report,\n",
        "           }"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oun_B6m5GXEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Log our parameters and results\n",
        "experiment.log_parameters(params)\n",
        "experiment.log_metric(\"report\",report)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuUPB_amTU-0",
        "colab_type": "text"
      },
      "source": [
        "If you're using comet within a jupyter notebook, it's important to end your experiment when you've finished as illustrated below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbQ3tKA-G6rW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "de0cb601-a392-40e9-9e82-84b3173306a4"
      },
      "source": [
        "experiment.end()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Comet.ml Experiment Summary\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO:   Data:\n",
            "COMET INFO:     display_summary_level : 1\n",
            "COMET INFO:     url                   : https://www.comet.ml/monicafar147/nlp-climate-change/7a98e5b6512f4fb09e348f5a7fde54da\n",
            "COMET INFO:   Metrics:\n",
            "COMET INFO:     report :               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.67      0.52      0.59       126\n",
            "           0       0.66      0.42      0.52       224\n",
            "           1       0.80      0.86      0.83       895\n",
            "           2       0.75      0.83      0.79       337\n",
            "\n",
            "    accuracy                           0.77      1582\n",
            "   macro avg       0.72      0.66      0.68      1582\n",
            "weighted avg       0.76      0.77      0.76      1582\n",
            "\n",
            "COMET INFO:   Parameters:\n",
            "COMET INFO:     classify_C                 : 1.0\n",
            "COMET INFO:     classify_class_weight      : 1\n",
            "COMET INFO:     classify_dual              : True\n",
            "COMET INFO:     classify_fit_intercept     : True\n",
            "COMET INFO:     classify_intercept_scaling : 1\n",
            "COMET INFO:     classify_loss              : squared_hinge\n",
            "COMET INFO:     classify_max_iter          : 1000\n",
            "COMET INFO:     classify_multi_class       : ovr\n",
            "COMET INFO:     classify_penalty           : l2\n",
            "COMET INFO:     classify_random_state      : 1\n",
            "COMET INFO:     classify_tol               : 0.0001\n",
            "COMET INFO:     classify_verbose           : 1\n",
            "COMET INFO:     keeps URL                  : splits URL up\n",
            "COMET INFO:     keeps hashtags             : True\n",
            "COMET INFO:     keeps username             : True\n",
            "COMET INFO:     model_type                 : LinearSVC\n",
            "COMET INFO:     preprocessing              : _preprocess_V3(data)\n",
            "COMET INFO:     removes puncutation        : string punctuation\n",
            "COMET INFO:     tfidf_analyzer             : word\n",
            "COMET INFO:     tfidf_binary               : 1\n",
            "COMET INFO:     tfidf_decode_error         : strict\n",
            "COMET INFO:     tfidf_dtype                : <class 'numpy.float64'>\n",
            "COMET INFO:     tfidf_encoding             : utf-8\n",
            "COMET INFO:     tfidf_input                : content\n",
            "COMET INFO:     tfidf_lowercase            : True\n",
            "COMET INFO:     tfidf_max_df               : 1.0\n",
            "COMET INFO:     tfidf_max_features         : 1\n",
            "COMET INFO:     tfidf_min_df               : 1\n",
            "COMET INFO:     tfidf_ngram_range          : (1, 1)\n",
            "COMET INFO:     tfidf_norm                 : l2\n",
            "COMET INFO:     tfidf_preprocessor         : 1\n",
            "COMET INFO:     tfidf_smooth_idf           : True\n",
            "COMET INFO:     tfidf_stop_words           : 1\n",
            "COMET INFO:     tfidf_strip_accents        : 1\n",
            "COMET INFO:     tfidf_sublinear_tf         : 1\n",
            "COMET INFO:     tfidf_token_pattern        : (?u)\\b\\w\\w+\\b\n",
            "COMET INFO:     tfidf_tokenizer            : 1\n",
            "COMET INFO:     tfidf_use_idf              : True\n",
            "COMET INFO:     tfidf_vocabulary           : 1\n",
            "COMET INFO:     use stopwords              : stopwords.words('english')\n",
            "COMET INFO:   Uploads:\n",
            "COMET INFO:     code                : 1 (5 KB)\n",
            "COMET INFO:     environment details : 1\n",
            "COMET INFO:     filename            : 1\n",
            "COMET INFO:     installed packages  : 1\n",
            "COMET INFO:     notebook            : 1\n",
            "COMET INFO:     os packages         : 1\n",
            "COMET INFO: ---------------------------\n",
            "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXuUORTEooIX",
        "colab_type": "text"
      },
      "source": [
        "## Display  \n",
        "\n",
        "Running `experiment.display()` will show you your experiments comet.ml page inside your notebook as illustrated below. You can do this immediately after an experiment is run, and logged. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-5ZmY-ZHFRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "outputId": "b0c8d992-677b-4468-d983-b75fb30ddcfb"
      },
      "source": [
        "experiment.display()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"800px\"\n",
              "            src=\"https://www.comet.ml/monicafar147/nlp-climate-change/8eaa856b64df4574ab38535e72a554e7\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "        ></iframe>\n",
              "        "
            ],
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7f1150c314a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fupy3YeZolRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    }
  ]
}